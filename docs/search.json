[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "learning diary",
    "section": "",
    "text": "1 Introduction\nThis is the introduction to my document.\n\n\n2 Week1\n\n\n3 Week6"
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "2  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "3  Week 1 - Introduction to Remote Sensing",
    "section": "",
    "text": "3.0.1 Summary\n\nRemote sensing is defined as acquiring information from a distance. Remote sensing can collect data without physical contact with objects by sensors.\nPassive or active sensors. Active sensors have an energy source and will actively emit electromagnetic energy and then receive\nElectromagnetic energy\n\nWavelength: long wavelength = low frequency = low energy\nElectromagnetic spectrum: total range of wavelengths of EM radiant\nEnergy interaction: reflected, absorbed by the surface, transmitted through the surface, scattered by particles in the atmosphere.\nBlue light shorter wavelength and more easily scatters(450nm-blue(shortest visible light) 550nm-green 700nm-red(longest)).\nThe spectral reflectance characteristics of surface materials are different. That is why sensors can identify materials. In the visible spectrum, chlorophyll in plant leaves strongly absorbs light in the blue and red regions, but reflects green light. This is why healthy vegetation appears green to our eyes.\nThe sun is the primary source of EM energy\n\nFour resolutions\n\nSpatial resolution the size of the raster grid per pixel\nSpectral resolution the number of bands sensor records data\nRadiometric resolution identify differences in light or reflectance, in practice this is the range of possible values.\nTemporal resolution the time it revisits\n\n\n\n\n3.0.2 Application\n\n3.0.2.1 Sentinel-2\n\nSpatial resolution of 10 m, 20 m and 60 m\nRevisiting every 10 days\nMulti-spectral data with 13 bands in the visible, near-infrared, and short-wave infrared part of the spectrum\n\n\nApplication\n\n\nMonitoring inland water bodies.\n\n\n\nWatching coastal waters.\n\n\n\n\n3.0.2.2 Landset\nThe below figures are my practical output\ngreen rectangle = bare earth pink rectangle = vegetation purple rectangle = urban area red rectangle = water\n It seems that the 7 bands.tif file is too large for my computer. I only export GeoTIFFS with bands 2,3,4.\nspectral profiles  density plot \n\n\n\n3.0.3 reflection\nThis is the very beginning of remote sensing, for me, it is the first contact for me with the subject. Almost everything is new for me. The only thing that I am familiar with is electromagnetic waves. Different wavelength gives electromagnetic waves different properties, like the penetrative ability. I thought longer wavelengths were easier to penetrate, while shorter wavelengths were more difficult. However, longer wavelengths of electromagnetic radiation, such as infrared and microwaves, tend to penetrate certain substances more easily. This is because some materials have lower absorption rates for longer wavelengths, allowing radiation of these wavelengths to penetrate relatively easily.\nFor other substances and specific wavelength ranges, the situation may be different. For example, some materials have high absorption rates for certain wavelengths of electromagnetic radiation, making it difficult for radiation of these wavelengths to penetrate the material. This is common in the visible light range, as many substances have high absorption rates for visible light, making it difficult for visible light to penetrate them. That is how the sensor identifies different materials. Also, remote sensing sensors can capture electromagnetic signals reflected or emitted from the Earth’s surface and divide them into multiple different bands. For example, a sensor for visible light and infrared might be divided into several different bands, each corresponding to a specific part of the visible light or infrared spectrum. Different bands capture information about different types of features on the Earth’s surface, so the choice of bands is crucial for the success of specific applications. That’s why when I do practicals there are so many bands that make me confused initially.\nAnother question I met that could take much time for me to figure out is what are the differences between satellites. I know they have different resolutions and bands, but what do the differences refer to, what advantages do they have, and Why are so many types of satellites needed?"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "4  Week 3 - Remote sensing data",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 Corrections\n\n4.1.1.1 Geometric\n\nFour reasons make image distortions:\n\n\nView angle\nTopography\nWind\nRotation of the earth (from satellite)\n\n\nSolution:\n\n\nseveral algorithms(linear regression, Helmert transformation,Polynomial algorithms 1-3, Thin Plate Spline (TPS), Projective transformation)\ndecide which model to be used(The model with the lowest RMSE will fit best)\nre-sample the final raster\n\n\n\n4.1.1.2 Atmospheric\n\nSources:\n\n\nAtmospheric scattering\nTopographic attenuation\n\n\nMethod:\n\n\nEmpirical Methods\nDark Object Subtraction\nPsuedo-invariant Features (PIFs)\nAtmospheric radiative transfer models\n\n\n\n4.1.1.3 Orthorectification / Topographic correction\n\nCosine correction\nMinnaert correction\nStatistical Empirical correction\nC Correction (advancing the Cosine)\n\n\n\n4.1.1.4 Radiometric Calibration\n\nRadiometric Calibration = Digital Number to spectral radiance(true spectral radiance on earth surfaces is different with spectral radiance that sensors capture)\nSensor calibration: We use measurements to adjust\nReflectance: A ratio comparing the quantity of light emitted by a target to the quantity of light incident upon it.\n\n\nshould be considered in radiance correction\n\n\n\n\n4.1.2 Joining data sets/Enhancements\n\n4.1.2.1 Joining data sets\n\nIf one image is not sufficient to cover the area we wish to study, we need to merge several images.\nis called ‘Mosaicking’ in remote sensing\nfeather images together\n\n\n\n4.1.2.2 Enhancements\n\nRatio\n\n\nto identify a certain landscape feature\nprinciple of NDVI: vegetation reflects more in the NIR but absorbs in the Red wavelength\n\n\nFiltering\nTexture\nData fusion\nPCA"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "4  Week 3 - Remote sensing data",
    "section": "4.2 Application",
    "text": "4.2 Application\nDue to its extensive history, simplicity, and utilization of readily accessible multi-spectral bands, the NDVI has emerged as the predominant index employed for evaluating vegetation(Huang et al., 2021). The article ‘Application of Normalized Difference Vegetation Index (NDVI) for the Detection of Extreme Precipitation Change’(Pei, Zhou and Xia, 2021) shows the application of NDVI in detecting extreme precipitation. NDVI can reflect extreme precipitation events because such events impact vegetation activity, potentially leading to lush vegetation and consequently higher NDVI values. By observing changes in NDVI values, one can assess variations in extreme precipitation. This study analyzed the application of minimum, average, and maximum NDVI in detecting extreme precipitation changes, using the middle and lower reaches of the Yangtze River as a case study. In this region, the location with the highest NDVI value represents the most vigorous vegetation growth. The study compared the performance of these three NDVI indicators in responding to extreme precipitation changes. They found that the maximum NDVI is more suitable for capturing the response of vegetation activity to extreme precipitation events. From my understanding, their approach involves setting a threshold to determine extreme precipitation events and then conducting separate correlation analyses between the three NDVI indicators and extreme precipitation intensity and frequency. The indicator with the highest correlation value is better at reflecting extreme precipitation events. Interestingly, the maximum NDVI value showed a negative correlation with extreme precipitation intensity and frequency, while the other two showed positive correlations. This implies that intense precipitation is detrimental to the growth of tall and lush vegetation. I speculate that intense precipitation may be accompanied by strong winds or other extreme weather conditions, which could potentially damage tall and lush vegetation."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "4  Week 3 - Remote sensing data",
    "section": "4.3 Reflection",
    "text": "4.3 Reflection\nThis week’s lesson on correction seems very similar to what we previously learned about data cleaning. Satellite images often have imperfections, and you need methods to correct them. Just like dealing with data in GIS and FSDS, you may need to remove NA values and handle outliers. Mosaicking is akin to merging or joining datasets, while enhancement involves processing the data to extract desired information, such as mean, extremes, and density. NDVI can highlight vegetation, and PCA can reduce dimensionality.\nThe article mentioned in my application made me realize that NDVI, besides analyzing vegetation information, can also be used to analyze factors related to vegetation changes, such as precipitation. This has broadened my perspective significantly."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nCloud Computing Platform\n\n5.1.1 Terms\n\nmage = raster\nFeature = vector\nImage stack= ImageCollection\nFeature stack (lots of polygons) = FeatureColletion\nImage scale = pixel resolution\n\n\n\n5.1.2 Language - javascript\n\nWebsite programming language\nsimilar to python and R\ndefine objects with var\ne.g\nvar object = {string: \"hello world\", int: 1, float: 1.1};\nprint('Print string:', object['string']);\nvar x = 10;\nprint(x)\n\n\n\n5.1.3 Server side\n\nSome codes that run on the server side\nGEE Objects = starting with ee stored on the server\nGEE function"
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "learning diary",
    "section": "",
    "text": "11"
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "learning diary",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]