[
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "7  Week 6 - classification 1",
    "section": "",
    "text": "7.0.1 Summary\nThis week we learned the application of machine learning in classification in remote sensing.\n\n7.0.1.1 Classification and Regression Trees (CART)\n\nuses a tree structure with nodes representing features, branches indicating decisions based on feature values, and leaf nodes showing predicted class labels (for classification) or numerical values (for regression)\nrecursively splits the feature space to maximize homogeneity within subsets, using measures like Gini impurity (for classification) or lowest SSR (for regression)\nallows controlling tree complexity with parameters like maximum depth and minimum samples per node, preventing overfitting and improving generalization.\n\n\n\n7.0.1.2 Random Forest\n\na machine learning algorithm based on ensemble learning. It consists of multiple decision trees, where each tree is a weak learner\nintroduces randomness to improve model generalization. It uses random sampling and random feature selection when building each decision tree, resulting in diversity among the trees(never all of them)\nemploys Bagging (Bootstrap Aggregating) to construct each decision tree. It creates multiple training sets by sampling from the original dataset with replacement, and builds a decision tree on each training set\nWhen constructing each decision tree, Random Forest randomly selects a subset of features to consider for splitting nodes, rather than using all features. This helps reduce feature correlation and increases model diversity\ndetermination of the prediction: the class with the most votes is selected as the final prediction for classification tasks, while for regression tasks, the average prediction of all trees is taken.\n\n\n\n7.0.1.3 Support Vector Machine (SVM) - Supervised classification\n\nlinear binary classifier - like logistic regression\nMaximum margin between two classes of training data = maximum margin classifier\nPoints on the boundaries (and within) are support vectors\nMiddle margin is called the separating hyperplane\nthe hyperplane is determined by finding the optimal decision boundary while penalizing misclassifications.\nThe parameter C controls the trade-off between maximizing the margin and minimizing the classification error.\nGamma (or Sigma) low = big radius for classified points, high = low radius for classified points\n\n\n\n\n7.0.2 Application\n\nSVM\n\nThis article ‘Support vector machines for classification in remote sensing’(Pal and Mather, 2005) demonstrates the excellent performance of Support Vector Machines (SVM) in classification tasks within the field of remote sensing. The study presents findings from two experiments, comparing multi-class SVMs with maximum likelihood (ML) and artificial neural network (ANN) methods regarding classification accuracy. The experiments involve land cover classification using multispectral (Landsat-7 ETM+) and hyperspectral (DAIS) data in test areas located in eastern England and central Spain, respectively. Our results demonstrate that SVM achieves superior classification accuracy compared to both ML and ANN classifiers. Furthermore, SVM exhibits effectiveness with small training datasets and high-dimensional data.\n\nRM\n\nIncreasing Ntree typically improves model performance as it reduces overfitting and enhances generalization by aggregating predictions from multiple trees. However, increasing Ntree also increases computational costs, so there is a trade-off between model performance and computational resources. Typically, an appropriate value for Ntree can be selected through experimentation or empirical knowledge to achieve the desired classification or regression outcome. So, when I was learning about random forest, I felt a bit confused about this empirically chosen parameter, Ntree. This article ‘Random forest in remote sensing: A review of applications and future directions’(Belgiu and Drăguţ, 2016) concludes, based on a review of other studies, that setting the default value of Ntree to 500 is acceptable when using the RF classifier on remotely sensed data.\n\n\n7.0.3 Reflection\nThis week, we focused on the application of machine learning in classification, which covered a lot of material similar to what we learned in casa006. Therefore, I found it relatively easy to understand. However, SVM was a method I wasn’t very familiar with, so I spent more time reading literature on this topic. I also discovered that SVM and Artificial Neural Networks are quite popular nowadays and yield accurate classification results. Nonetheless, I feel that machine learning encompasses a vast amount of knowledge, and I have only scratched the surface. I believe I need to dedicate more time to learning in order to deepen my understanding of machine learning."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "5  Week 3 - Remote sensing data",
    "section": "",
    "text": "5.0.1 Summary\n\n5.0.1.1 Corrections\n\n5.0.1.1.1 Geometric\n\nFour reasons make image distortions:\n\n\nView angle\nTopography\nWind\nRotation of the earth (from satellite)\n\n\nSolution:\n\n\nseveral algorithms(linear regression, Helmert transformation,Polynomial algorithms 1-3, Thin Plate Spline (TPS), Projective transformation)\ndecide which model to be used(The model with the lowest RMSE will fit best)\nre-sample the final raster\n\n\n\n5.0.1.1.2 Atmospheric\n\nSources:\n\n\nAtmospheric scattering\nTopographic attenuation\n\n\nMethod:\n\n\nEmpirical Methods\nDark Object Subtraction\nPsuedo-invariant Features (PIFs)\nAtmospheric radiative transfer models\n\n\n\n5.0.1.1.3 Orthorectification / Topographic correction\n\nCosine correction\nMinnaert correction\nStatistical Empirical correction\nC Correction (advancing the Cosine)\n\n\n\n5.0.1.1.4 Radiometric Calibration\n\nRadiometric Calibration = Digital Number to spectral radiance(true spectral radiance on earth surfaces is different with spectral radiance that sensors capture)\nSensor calibration: We use measurements to adjust\nReflectance: A ratio comparing the quantity of light emitted by a target to the quantity of light incident upon it.\n\n\nshould be considered in radiance correction\n\n\n\n\n5.0.1.2 Joining data sets/Enhancements\n\n5.0.1.2.1 Joining data sets\n\nIf one image is not sufficient to cover the area we wish to study, we need to merge several images.\nis called ‘Mosaicking’ in remote sensing\nfeather images together\n\n\n\n5.0.1.2.2 Enhancements\n\nRatio\n\n\nto identify a certain landscape feature\nprinciple of NDVI: vegetation reflects more in the NIR but absorbs in the Red wavelength\n\n\nFiltering\nTexture\nData fusion\nPCA\n\n\n\n\n\n5.0.2 Application\nDue to its extensive history, simplicity, and utilization of readily accessible multi-spectral bands, the NDVI has emerged as the predominant index employed for evaluating vegetation(Huang et al., 2021). The article ‘Application of Normalized Difference Vegetation Index (NDVI) for the Detection of Extreme Precipitation Change’(Pei, Zhou and Xia, 2021) shows the application of NDVI in detecting extreme precipitation. NDVI can reflect extreme precipitation events because such events impact vegetation activity, potentially leading to lush vegetation and consequently higher NDVI values. By observing changes in NDVI values, one can assess variations in extreme precipitation. This study analyzed the application of minimum, average, and maximum NDVI in detecting extreme precipitation changes, using the middle and lower reaches of the Yangtze River as a case study. In this region, the location with the highest NDVI value represents the most vigorous vegetation growth. The study compared the performance of these three NDVI indicators in responding to extreme precipitation changes. They found that the maximum NDVI is more suitable for capturing the response of vegetation activity to extreme precipitation events. From my understanding, their approach involves setting a threshold to determine extreme precipitation events and then conducting separate correlation analyses between the three NDVI indicators and extreme precipitation intensity and frequency. The indicator with the highest correlation value is better at reflecting extreme precipitation events. Interestingly, the maximum NDVI value showed a negative correlation with extreme precipitation intensity and frequency, while the other two showed positive correlations. This implies that intense precipitation is detrimental to the growth of tall and lush vegetation. I speculate that intense precipitation may be accompanied by strong winds or other extreme weather conditions, which could potentially damage tall and lush vegetation.\n\n\n5.0.3 Reflection\nThis week’s lesson on correction seems very similar to what we previously learned about data cleaning. Satellite images often have imperfections, and you need methods to correct them. Just like dealing with data in GIS and FSDS, you may need to remove NA values and handle outliers. Mosaicking is akin to merging or joining datasets, while enhancement involves processing the data to extract desired information, such as mean, extremes, and density. NDVI can highlight vegetation, and PCA can reduce dimensionality.\nThe article mentioned in my application made me realize that NDVI, besides analyzing vegetation information, can also be used to analyze factors related to vegetation changes, such as precipitation. This has broadened my perspective significantly."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "6  Week 5 - Google Earth Engine",
    "section": "",
    "text": "6.0.1 Summary\nCloud Computing Platform for planetary-scale geospatial analysis\n\n6.0.1.1 Terms\n\nmage = raster\nFeature = vector\nImage stack= ImageCollection\nFeature stack (lots of polygons) = FeatureColletion\nImage scale = pixel resolution\n\n\n\n6.0.1.2 Language - javascript\n\nWebsite programming language\nsimilar to Python and R\ndefine objects with var\ne.g\nvar object = {string: \"hello world\", int: 1, float: 1.1};\nprint('Print string:', object['string']);\nvar x = 10;\nprint(x)\n\n\n\n6.0.1.3 Server side\n\nSome codes that run on the server side\nGEE Objects = starting with ee stored on the server\nOverview of GEE functions \n\n\n\n6.0.1.4 Advantages and limitations\n\n\n\n6.0.1.5 Overview of GEE Code Editor\n\n\n(Source: Google Earth Engine)\n\n\n\n\n6.0.2 Application\n\nThis is a summary of the applications of GEE \n\n(Source: M. Amani et al., 2020)\n\n\nA specific example of an application is that Hansen et al. (2013) utilized decision trees generated from extensive training data and a deep stack of metrics computed from Landsat scenes to characterize forest extent, loss, and gain from 2000 to 2012(Gorelick et al., 2017). The article ‘High-Resolution Global Maps of 21st-Century Forest Cover Change’(Hansen et al., 2013) investigates global forest cover change from 2000 to 2012 using data with a spatial resolution of 30 meters. This high-resolution global study represents a significant advancement over previous studies conducted at coarser scales. The study quantifies forest loss and gain using specific methodologies and provides annual loss information. This detailed quantification offers more accurate data, facilitating a deeper understanding of forest change trends. By employing spatially explicit methods, the study results are more precise and interpretable in spatial terms. This enhances the ability to accurately locate and analyze factors and patterns influencing forest cover change. GEE facilitated the processing of large-scale Landsat imagery datasets, allowing for efficient computation of metrics and decision tree generation. This enabled the researchers to analyze forest cover change globally over a significant period. GEE’s capabilities were leveraged to conduct spatially explicit analyses, enabling the researchers to map forest cover extent, loss, and gain at a high spatial resolution of 30 meters. This spatial specificity provided detailed insights into global forest dynamics.\n\n\n6.0.3 Reflection\nThis week, we learned a new tool for research called Google Earth Engine, which allows us to run code on servers. During the practical exercises, I noticed a significant increase in speed compared to running code locally, especially when compared to tools like SNAP, which felt quite slow. Tasks such as Mosaic images, Clip images, Texture measures, and PCA, which we previously learned, can all be completed on Google Earth Engine’s servers. The only difference is that Google Earth Engine uses a different programming language, JavaScript, which I wasn’t very familiar with at the beginning. However, as I followed along with the practical exercises, I found that its logic is similar to Python and R, which made it easier for me to pick up. As a result, I became more and more proficient with it as I progressed through the exercises."
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "learning diary",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  }
]