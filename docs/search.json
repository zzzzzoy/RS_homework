[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "learning diary",
    "section": "",
    "text": "1 Introduction\nThis is the introduction to my document.\n\n\n2 Week1\n\n\n3 Week6"
  },
  {
    "objectID": "week3.html#summary",
    "href": "week3.html#summary",
    "title": "5  Week 3 - Remote sensing data",
    "section": "5.1 Summary",
    "text": "5.1 Summary\n\n5.1.1 Corrections\n\n5.1.1.1 Geometric\n\nFour reasons make image distortions:\n\n\nView angle\nTopography\nWind\nRotation of the earth (from satellite)\n\n\nSolution:\n\n\nseveral algorithms(linear regression, Helmert transformation,Polynomial algorithms 1-3, Thin Plate Spline (TPS), Projective transformation)\ndecide which model to be used(The model with the lowest RMSE will fit best)\nre-sample the final raster\n\n\n\n5.1.1.2 Atmospheric\n\nSources:\n\n\nAtmospheric scattering\nTopographic attenuation\n\n\nMethod:\n\n\nEmpirical Methods\nDark Object Subtraction\nPsuedo-invariant Features (PIFs)\nAtmospheric radiative transfer models\n\n\n\n5.1.1.3 Orthorectification / Topographic correction\n\nCosine correction\nMinnaert correction\nStatistical Empirical correction\nC Correction (advancing the Cosine)\n\n\n\n5.1.1.4 Radiometric Calibration\n\nRadiometric Calibration = Digital Number to spectral radiance(true spectral radiance on earth surfaces is different with spectral radiance that sensors capture)\nSensor calibration: We use measurements to adjust\nReflectance: A ratio comparing the quantity of light emitted by a target to the quantity of light incident upon it.\n\n\nshould be considered in radiance correction\n\n\n\n\n5.1.2 Joining data sets/Enhancements\n\n5.1.2.1 Joining data sets\n\nIf one image is not sufficient to cover the area we wish to study, we need to merge several images.\nis called ‘Mosaicking’ in remote sensing\nfeather images together\n\n\n\n5.1.2.2 Enhancements\n\nRatio\n\n\nto identify a certain landscape feature\nprinciple of NDVI: vegetation reflects more in the NIR but absorbs in the Red wavelength\n\n\nFiltering\nTexture\nData fusion\nPCA"
  },
  {
    "objectID": "week3.html#application",
    "href": "week3.html#application",
    "title": "5  Week 3 - Remote sensing data",
    "section": "5.2 Application",
    "text": "5.2 Application\nDue to its extensive history, simplicity, and utilization of readily accessible multi-spectral bands, the NDVI has emerged as the predominant index employed for evaluating vegetation(Huang et al., 2021). The article ‘Application of Normalized Difference Vegetation Index (NDVI) for the Detection of Extreme Precipitation Change’(Pei, Zhou and Xia, 2021) shows the application of NDVI in detecting extreme precipitation. NDVI can reflect extreme precipitation events because such events impact vegetation activity, potentially leading to lush vegetation and consequently higher NDVI values. By observing changes in NDVI values, one can assess variations in extreme precipitation. This study analyzed the application of minimum, average, and maximum NDVI in detecting extreme precipitation changes, using the middle and lower reaches of the Yangtze River as a case study. In this region, the location with the highest NDVI value represents the most vigorous vegetation growth. The study compared the performance of these three NDVI indicators in responding to extreme precipitation changes. They found that the maximum NDVI is more suitable for capturing the response of vegetation activity to extreme precipitation events. From my understanding, their approach involves setting a threshold to determine extreme precipitation events and then conducting separate correlation analyses between the three NDVI indicators and extreme precipitation intensity and frequency. The indicator with the highest correlation value is better at reflecting extreme precipitation events. Interestingly, the maximum NDVI value showed a negative correlation with extreme precipitation intensity and frequency, while the other two showed positive correlations. This implies that intense precipitation is detrimental to the growth of tall and lush vegetation. I speculate that intense precipitation may be accompanied by strong winds or other extreme weather conditions, which could potentially damage tall and lush vegetation."
  },
  {
    "objectID": "week3.html#reflection",
    "href": "week3.html#reflection",
    "title": "5  Week 3 - Remote sensing data",
    "section": "5.3 Reflection",
    "text": "5.3 Reflection\nThis week’s lesson on correction seems very similar to what we previously learned about data cleaning. Satellite images often have imperfections, and you need methods to correct them. Just like dealing with data in GIS and FSDS, you may need to remove NA values and handle outliers. Mosaicking is akin to merging or joining datasets, while enhancement involves processing the data to extract desired information, such as mean, extremes, and density. NDVI can highlight vegetation, and PCA can reduce dimensionality.\nThe article mentioned in my application made me realize that NDVI, besides analyzing vegetation information, can also be used to analyze factors related to vegetation changes, such as precipitation. This has broadened my perspective significantly."
  },
  {
    "objectID": "week5.html#summary",
    "href": "week5.html#summary",
    "title": "6  Week 5 - Google Earth Engine",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nCloud Computing Platform for planetary-scale geospatial analysis\n\n6.1.1 Terms\n\nmage = raster\nFeature = vector\nImage stack= ImageCollection\nFeature stack (lots of polygons) = FeatureColletion\nImage scale = pixel resolution\n\n\n\n6.1.2 Language - javascript\n\nWebsite programming language\nsimilar to Python and R\ndefine objects with var\ne.g\nvar object = {string: \"hello world\", int: 1, float: 1.1};\nprint('Print string:', object['string']);\nvar x = 10;\nprint(x)\n\n\n\n6.1.3 Server side\n\nSome codes that run on the server side\nGEE Objects = starting with ee stored on the server\nOverview of GEE functions \n\n\n\n6.1.4 Advantages and limitations\n\n\n\n6.1.5 Overview of GEE Code Editor\n\n\n(Source: Google Earth Engine)"
  },
  {
    "objectID": "week5.html#application",
    "href": "week5.html#application",
    "title": "6  Week 5 - Google Earth Engine",
    "section": "6.2 Application",
    "text": "6.2 Application\n\nThis is a summary of the applications of GEE \n\n(Source: M. Amani et al., 2020)\n\n\nA specific example of an application is that Hansen et al. (2013) utilized decision trees generated from extensive training data and a deep stack of metrics computed from Landsat scenes to characterize forest extent, loss, and gain from 2000 to 2012(Gorelick et al., 2017). The article ‘High-Resolution Global Maps of 21st-Century Forest Cover Change’(Hansen et al., 2013) investigates global forest cover change from 2000 to 2012 using data with a spatial resolution of 30 meters. This high-resolution global study represents a significant advancement over previous studies conducted at coarser scales. The study quantifies forest loss and gain using specific methodologies and provides annual loss information. This detailed quantification offers more accurate data, facilitating a deeper understanding of forest change trends. By employing spatially explicit methods, the study results are more precise and interpretable in spatial terms. This enhances the ability to accurately locate and analyze factors and patterns influencing forest cover change. GEE facilitated the processing of large-scale Landsat imagery datasets, allowing for efficient computation of metrics and decision tree generation. This enabled the researchers to analyze forest cover change globally over a significant period. GEE’s capabilities were leveraged to conduct spatially explicit analyses, enabling the researchers to map forest cover extent, loss, and gain at a high spatial resolution of 30 meters. This spatial specificity provided detailed insights into global forest dynamics."
  },
  {
    "objectID": "week6.html",
    "href": "week6.html",
    "title": "learning diary",
    "section": "",
    "text": "11"
  },
  {
    "objectID": "week7.html",
    "href": "week7.html",
    "title": "learning diary",
    "section": "",
    "text": "1"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "week2.html",
    "href": "week2.html",
    "title": "4  Week 2 - Xaringan",
    "section": "",
    "text": "github link: https://github.com/zzzzzoy/RS_xaringan"
  },
  {
    "objectID": "week1.html",
    "href": "week1.html",
    "title": "3  Week 1 - Introduction to Remote Sensing",
    "section": "",
    "text": "3.0.1 Summary\n\nRemote sensing is defined as acquiring information from a distance. Remote sensing can collect data without physical contact with objects by sensors.\nPassive or active sensors. Active sensors have an energy source and will actively emit electromagnetic energy and then receive\nElectromagnetic energy\n\nWavelength: long wavelength = low frequency = low energy\nElectromagnetic spectrum: total range of wavelengths of EM radiant\nEnergy interaction: reflected, absorbed by the surface, transmitted through the surface, scattered by particles in the atmosphere.\nBlue light shorter wavelength and more easily scatters(450nm-blue(shortest visible light) 550nm-green 700nm-red(longest)).\nThe spectral reflectance characteristics of surface materials are different. That is why sensors can identify materials. In the visible spectrum, chlorophyll in plant leaves strongly absorbs light in the blue and red regions, but reflects green light. This is why healthy vegetation appears green to our eyes.\nThe sun is the primary source of EM energy\n\nFour resolutions\n\nSpatial resolution the size of the raster grid per pixel\nSpectral resolution the number of bands sensor records data\nRadiometric resolution identify differences in light or reflectance, in practice this is the range of possible values.\nTemporal resolution the time it revisits\n\n\n\n\n3.0.2 Application\n\n3.0.2.1 Sentinel-2\n\nSpatial resolution of 10 m, 20 m and 60 m\nRevisiting every 10 days\nMulti-spectral data with 13 bands in the visible, near-infrared, and short-wave infrared part of the spectrum\n\n\nApplication\n\n\nMonitoring inland water bodies.\n\n\n\nWatching coastal waters.\n\n\n\n\n3.0.2.2 Landset\nThe below figures are my practical output\ngreen rectangle = bare earth pink rectangle = vegetation purple rectangle = urban area red rectangle = water\n\nIt seems that the 7 bands.tif file is too large for my computer. I only export GeoTIFFS with bands 2,3,4.\nspectral profiles\n\ndensity plot\n\n\n\n\n3.0.3 reflection\nThis is the very beginning of remote sensing, for me, it is the first contact for me with the subject. Almost everything is new for me. The only thing that I am familiar with is electromagnetic waves. Different wavelength gives electromagnetic waves different properties, like the penetrative ability. I thought longer wavelengths were easier to penetrate, while shorter wavelengths were more difficult. However, longer wavelengths of electromagnetic radiation, such as infrared and microwaves, tend to penetrate certain substances more easily. This is because some materials have lower absorption rates for longer wavelengths, allowing radiation of these wavelengths to penetrate relatively easily.\nFor other substances and specific wavelength ranges, the situation may be different. For example, some materials have high absorption rates for certain wavelengths of electromagnetic radiation, making it difficult for radiation of these wavelengths to penetrate the material. This is common in the visible light range, as many substances have high absorption rates for visible light, making it difficult for visible light to penetrate them. That is how the sensor identifies different materials. Also, remote sensing sensors can capture electromagnetic signals reflected or emitted from the Earth’s surface and divide them into multiple different bands. For example, a sensor for visible light and infrared might be divided into several different bands, each corresponding to a specific part of the visible light or infrared spectrum. Different bands capture information about different types of features on the Earth’s surface, so the choice of bands is crucial for the success of specific applications. That’s why when I do practicals there are so many bands that make me confused initially.\nAnother question I met that could take much time for me to figure out is what are the differences between satellites. I know they have different resolutions and bands, but what do the differences refer to, what advantages do they have, and Why are so many types of satellites needed?"
  },
  {
    "objectID": "week5.html#reflection",
    "href": "week5.html#reflection",
    "title": "6  Week 5 - Google Earth Engine",
    "section": "6.3 Reflection",
    "text": "6.3 Reflection\nThis week, we learned a new tool for research called Google Earth Engine, which allows us to run code on servers. During the practical exercises, I noticed a significant increase in speed compared to running code locally, especially when compared to tools like SNAP, which felt quite slow. Tasks such as Mosaic images, Clip images, Texture measures, and PCA, which we previously learned, can all be completed on Google Earth Engine’s servers. The only difference is that Google Earth Engine uses a different programming language, JavaScript, which I wasn’t very familiar with at the beginning. However, as I followed along with the practical exercises, I found that its logic is similar to Python and R, which made it easier for me to pick up. As a result, I became more and more proficient with it as I progressed through the exercises."
  },
  {
    "objectID": "week6.html#summary",
    "href": "week6.html#summary",
    "title": "7  Week 6 - classification 1",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nThis week we learned the application of machine learning in classification in remote sensing.\n\n7.1.1 Classification and Regression Trees (CART)\n\nuses a tree structure with nodes representing features, branches indicating decisions based on feature values, and leaf nodes showing predicted class labels (for classification) or numerical values (for regression)\nrecursively splits the feature space to maximize homogeneity within subsets, using measures like Gini impurity (for classification) or lowest SSR (for regression)\nallows controlling tree complexity with parameters like maximum depth and minimum samples per node, preventing overfitting and improving generalization.\n\n\n\n7.1.2 Random Forest\n\na machine learning algorithm based on ensemble learning. It consists of multiple decision trees, where each tree is a weak learner\nintroduces randomness to improve model generalization. It uses random sampling and random feature selection when building each decision tree, resulting in diversity among the trees(never all of them)\nemploys Bagging (Bootstrap Aggregating) to construct each decision tree. It creates multiple training sets by sampling from the original dataset with replacement, and builds a decision tree on each training set\nWhen constructing each decision tree, Random Forest randomly selects a subset of features to consider for splitting nodes, rather than using all features. This helps reduce feature correlation and increases model diversity\ndetermination of the prediction: the class with the most votes is selected as the final prediction for classification tasks, while for regression tasks, the average prediction of all trees is taken."
  },
  {
    "objectID": "week5.html",
    "href": "week5.html",
    "title": "6  Week 5 - Google Earth Engine",
    "section": "",
    "text": "6.0.1 Summary\nCloud Computing Platform for planetary-scale geospatial analysis\n\n6.0.1.1 Terms\n\nmage = raster\nFeature = vector\nImage stack= ImageCollection\nFeature stack (lots of polygons) = FeatureColletion\nImage scale = pixel resolution\n\n\n\n6.0.1.2 Language - javascript\n\nWebsite programming language\nsimilar to Python and R\ndefine objects with var\ne.g\nvar object = {string: \"hello world\", int: 1, float: 1.1};\nprint('Print string:', object['string']);\nvar x = 10;\nprint(x)\n\n\n\n6.0.1.3 Server side\n\nSome codes that run on the server side\nGEE Objects = starting with ee stored on the server\nOverview of GEE functions \n\n\n\n6.0.1.4 Advantages and limitations\n\n\n\n6.0.1.5 Overview of GEE Code Editor\n\n\n(Source: Google Earth Engine)\n\n\n\n\n6.0.2 Application\n\nThis is a summary of the applications of GEE \n\n(Source: M. Amani et al., 2020)\n\n\nA specific example of an application is that Hansen et al. (2013) utilized decision trees generated from extensive training data and a deep stack of metrics computed from Landsat scenes to characterize forest extent, loss, and gain from 2000 to 2012(Gorelick et al., 2017). The article ‘High-Resolution Global Maps of 21st-Century Forest Cover Change’(Hansen et al., 2013) investigates global forest cover change from 2000 to 2012 using data with a spatial resolution of 30 meters. This high-resolution global study represents a significant advancement over previous studies conducted at coarser scales. The study quantifies forest loss and gain using specific methodologies and provides annual loss information. This detailed quantification offers more accurate data, facilitating a deeper understanding of forest change trends. By employing spatially explicit methods, the study results are more precise and interpretable in spatial terms. This enhances the ability to accurately locate and analyze factors and patterns influencing forest cover change. GEE facilitated the processing of large-scale Landsat imagery datasets, allowing for efficient computation of metrics and decision tree generation. This enabled the researchers to analyze forest cover change globally over a significant period. GEE’s capabilities were leveraged to conduct spatially explicit analyses, enabling the researchers to map forest cover extent, loss, and gain at a high spatial resolution of 30 meters. This spatial specificity provided detailed insights into global forest dynamics.\n\n\n6.0.3 Reflection\nThis week, we learned a new tool for research called Google Earth Engine, which allows us to run code on servers. During the practical exercises, I noticed a significant increase in speed compared to running code locally, especially when compared to tools like SNAP, which felt quite slow. Tasks such as Mosaic images, Clip images, Texture measures, and PCA, which we previously learned, can all be completed on Google Earth Engine’s servers. The only difference is that Google Earth Engine uses a different programming language, JavaScript, which I wasn’t very familiar with at the beginning. However, as I followed along with the practical exercises, I found that its logic is similar to Python and R, which made it easier for me to pick up. As a result, I became more and more proficient with it as I progressed through the exercises."
  },
  {
    "objectID": "week3.html",
    "href": "week3.html",
    "title": "5  Week 3 - Remote sensing data",
    "section": "",
    "text": "5.0.1 Summary\n\n5.0.1.1 Corrections\n\n5.0.1.1.1 Geometric\n\nFour reasons make image distortions:\n\n\nView angle\nTopography\nWind\nRotation of the earth (from satellite)\n\n\nSolution:\n\n\nseveral algorithms(linear regression, Helmert transformation,Polynomial algorithms 1-3, Thin Plate Spline (TPS), Projective transformation)\ndecide which model to be used(The model with the lowest RMSE will fit best)\nre-sample the final raster\n\n\n\n5.0.1.1.2 Atmospheric\n\nSources:\n\n\nAtmospheric scattering\nTopographic attenuation\n\n\nMethod:\n\n\nEmpirical Methods\nDark Object Subtraction\nPsuedo-invariant Features (PIFs)\nAtmospheric radiative transfer models\n\n\n\n5.0.1.1.3 Orthorectification / Topographic correction\n\nCosine correction\nMinnaert correction\nStatistical Empirical correction\nC Correction (advancing the Cosine)\n\n\n\n5.0.1.1.4 Radiometric Calibration\n\nRadiometric Calibration = Digital Number to spectral radiance(true spectral radiance on earth surfaces is different with spectral radiance that sensors capture)\nSensor calibration: We use measurements to adjust\nReflectance: A ratio comparing the quantity of light emitted by a target to the quantity of light incident upon it.\n\n\nshould be considered in radiance correction\n\n\n\n\n5.0.1.2 Joining data sets/Enhancements\n\n5.0.1.2.1 Joining data sets\n\nIf one image is not sufficient to cover the area we wish to study, we need to merge several images.\nis called ‘Mosaicking’ in remote sensing\nfeather images together\n\n\n\n5.0.1.2.2 Enhancements\n\nRatio\n\n\nto identify a certain landscape feature\nprinciple of NDVI: vegetation reflects more in the NIR but absorbs in the Red wavelength\n\n\nFiltering\nTexture\nData fusion\nPCA\n\n\n\n\n\n5.0.2 Application\nDue to its extensive history, simplicity, and utilization of readily accessible multi-spectral bands, the NDVI has emerged as the predominant index employed for evaluating vegetation(Huang et al., 2021). The article ‘Application of Normalized Difference Vegetation Index (NDVI) for the Detection of Extreme Precipitation Change’(Pei, Zhou and Xia, 2021) shows the application of NDVI in detecting extreme precipitation. NDVI can reflect extreme precipitation events because such events impact vegetation activity, potentially leading to lush vegetation and consequently higher NDVI values. By observing changes in NDVI values, one can assess variations in extreme precipitation. This study analyzed the application of minimum, average, and maximum NDVI in detecting extreme precipitation changes, using the middle and lower reaches of the Yangtze River as a case study. In this region, the location with the highest NDVI value represents the most vigorous vegetation growth. The study compared the performance of these three NDVI indicators in responding to extreme precipitation changes. They found that the maximum NDVI is more suitable for capturing the response of vegetation activity to extreme precipitation events. From my understanding, their approach involves setting a threshold to determine extreme precipitation events and then conducting separate correlation analyses between the three NDVI indicators and extreme precipitation intensity and frequency. The indicator with the highest correlation value is better at reflecting extreme precipitation events. Interestingly, the maximum NDVI value showed a negative correlation with extreme precipitation intensity and frequency, while the other two showed positive correlations. This implies that intense precipitation is detrimental to the growth of tall and lush vegetation. I speculate that intense precipitation may be accompanied by strong winds or other extreme weather conditions, which could potentially damage tall and lush vegetation.\n\n\n5.0.3 Reflection\nThis week’s lesson on correction seems very similar to what we previously learned about data cleaning. Satellite images often have imperfections, and you need methods to correct them. Just like dealing with data in GIS and FSDS, you may need to remove NA values and handle outliers. Mosaicking is akin to merging or joining datasets, while enhancement involves processing the data to extract desired information, such as mean, extremes, and density. NDVI can highlight vegetation, and PCA can reduce dimensionality.\nThe article mentioned in my application made me realize that NDVI, besides analyzing vegetation information, can also be used to analyze factors related to vegetation changes, such as precipitation. This has broadened my perspective significantly."
  }
]